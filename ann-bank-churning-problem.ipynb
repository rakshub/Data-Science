{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10586734,"sourceType":"datasetVersion","datasetId":6551854}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-26T16:26:10.483881Z","iopub.execute_input":"2025-01-26T16:26:10.484224Z","iopub.status.idle":"2025-01-26T16:26:10.491708Z","shell.execute_reply.started":"2025-01-26T16:26:10.484197Z","shell.execute_reply":"2025-01-26T16:26:10.490547Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/churn-dataset/Churn_Modelling.csv\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler,LabelEncoder,OnehotEncoder\nimport pickle\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T16:26:10.493449Z","iopub.execute_input":"2025-01-26T16:26:10.494107Z","iopub.status.idle":"2025-01-26T16:26:10.523257Z","shell.execute_reply.started":"2025-01-26T16:26:10.494064Z","shell.execute_reply":"2025-01-26T16:26:10.519769Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-9a683b4ea570>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLabelEncoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mOnehotEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'OnehotEncoder' from 'sklearn.preprocessing' (/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/__init__.py)"],"ename":"ImportError","evalue":"cannot import name 'OnehotEncoder' from 'sklearn.preprocessing' (/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/__init__.py)","output_type":"error"}],"execution_count":8},{"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/churn-dataset/Churn_Modelling.csv\")\ndata","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T16:26:10.524003Z","iopub.status.idle":"2025-01-26T16:26:10.524478Z","shell.execute_reply":"2025-01-26T16:26:10.524282Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data=data.drop([\"RowNumber\",\"CustomerId\",\"Surname\"],axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T16:26:10.525732Z","iopub.status.idle":"2025-01-26T16:26:10.526229Z","shell.execute_reply":"2025-01-26T16:26:10.525998Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Encode categorical variables\nlabel_encoder_gender=LabelEncoder()\ndata['Gender']=label_encoder_gender.fit_transform(data['Gender'])\ndata","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T16:26:10.527023Z","iopub.status.idle":"2025-01-26T16:26:10.527480Z","shell.execute_reply":"2025-01-26T16:26:10.527265Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Onehot encode 'Geography\nfrom sklearn.preprocessing import OneHotEncoder\nonehot_encoder_geo=OneHotEncoder()\ngeo_encoder=onehot_encoder_geo.fit_transform(data[['Geography']]).toarray()\ngeo_encoder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T16:26:10.528404Z","iopub.status.idle":"2025-01-26T16:26:10.528843Z","shell.execute_reply":"2025-01-26T16:26:10.528659Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"onehot_encoder_geo.get_feature_names_out(['Geography'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T16:26:10.530069Z","iopub.status.idle":"2025-01-26T16:26:10.530525Z","shell.execute_reply":"2025-01-26T16:26:10.530305Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"geo_encoded_df=pd.DataFrame(geo_encoder,columns=onehot_encoder_geo.get_feature_names_out(['Geography']))\ngeo_encoded_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T16:26:10.531682Z","iopub.status.idle":"2025-01-26T16:26:10.532113Z","shell.execute_reply":"2025-01-26T16:26:10.531906Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Combine one hot encoder columns with the original data\ndata=pd.concat([data.drop('Geography',axis=1),geo_encoded_df],axis=1)\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T16:26:10.533863Z","iopub.status.idle":"2025-01-26T16:26:10.534498Z","shell.execute_reply":"2025-01-26T16:26:10.534264Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Save the encoders and sscaler\nwith open('label_encoder_gender.pkl','wb') as file:\n    pickle.dump(label_encoder_gender,file)\n\nwith open('onehot_encoder_geo.pkl','wb') as file:\n    pickle.dump(onehot_encoder_geo,file)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T16:26:10.536703Z","iopub.status.idle":"2025-01-26T16:26:10.537214Z","shell.execute_reply":"2025-01-26T16:26:10.537018Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## DiVide the dataset into indepent and dependent features\nX=data.drop('Exited',axis=1)\ny=data['Exited']\n\n## Split the data in training and tetsing sets\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n\n## Scale these features\nscaler=StandardScaler()\nX_train=scaler.fit_transform(X_train)\nX_test=scaler.transform(X_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T16:26:10.538539Z","iopub.status.idle":"2025-01-26T16:26:10.539041Z","shell.execute_reply":"2025-01-26T16:26:10.538831Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open('scaler.pkl','wb') as file:\n    pickle.dump(scaler,file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T16:26:10.540142Z","iopub.status.idle":"2025-01-26T16:26:10.540561Z","shell.execute_reply":"2025-01-26T16:26:10.540375Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.callbacks import EarlyStopping,TensorBoard\nimport datetime","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T16:26:10.541514Z","iopub.status.idle":"2025-01-26T16:26:10.541931Z","shell.execute_reply":"2025-01-26T16:26:10.541720Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Build Our ANN Model\nmodel=Sequential([\n    Dense(64,activation='relu',input_shape=(X_train.shape[1],)), ## HL1 Connected wwith input layer\n    Dense(32,activation='relu'), ## HL2\n    Dense(1,activation='sigmoid')  ## output layer\n]\n\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T16:26:10.542819Z","iopub.status.idle":"2025-01-26T16:26:10.543241Z","shell.execute_reply":"2025-01-26T16:26:10.543052Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T16:26:10.544357Z","iopub.status.idle":"2025-01-26T16:26:10.544835Z","shell.execute_reply":"2025-01-26T16:26:10.544621Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow\nopt=tensorflow.keras.optimizers.Adam(learning_rate=0.01)\nloss=tensorflow.keras.losses.BinaryCrossentropy()\nloss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T16:26:10.545662Z","iopub.status.idle":"2025-01-26T16:26:10.545950Z","shell.execute_reply":"2025-01-26T16:26:10.545835Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## compile the model\nmodel.compile(optimizer=opt,loss=\"binary_crossentropy\",metrics=['accuracy'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T16:26:10.546805Z","iopub.status.idle":"2025-01-26T16:26:10.547223Z","shell.execute_reply":"2025-01-26T16:26:10.547043Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Set up the Tensorboard\nfrom tensorflow.keras.callbacks import EarlyStopping,TensorBoard\n\nlog_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorflow_callback=TensorBoard(log_dir=log_dir,histogram_freq=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T16:26:10.548056Z","iopub.status.idle":"2025-01-26T16:26:10.548545Z","shell.execute_reply":"2025-01-26T16:26:10.548295Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Set up Early Stopping\nearly_stopping_callback=EarlyStopping(monitor='val_loss',patience=10,restore_best_weights=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T16:26:10.549464Z","iopub.status.idle":"2025-01-26T16:26:10.549930Z","shell.execute_reply":"2025-01-26T16:26:10.549731Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### Train the model\nhistory=model.fit(\n    X_train,y_train,validation_data=(X_test,y_test),epochs=100,\n    callbacks=[tensorflow_callback,early_stopping_callback]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T16:26:10.550989Z","iopub.status.idle":"2025-01-26T16:26:10.551418Z","shell.execute_reply":"2025-01-26T16:26:10.551231Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save('model.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T16:26:10.553523Z","iopub.status.idle":"2025-01-26T16:26:10.554115Z","shell.execute_reply":"2025-01-26T16:26:10.553917Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Load Tensorboard Extension\n%load_ext tensorboard","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T16:26:10.559044Z","iopub.status.idle":"2025-01-26T16:26:10.559534Z","shell.execute_reply":"2025-01-26T16:26:10.559311Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%tensorboard --logdir logs/fit","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}